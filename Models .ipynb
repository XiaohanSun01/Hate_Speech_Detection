{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72aa9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc, precision_score, recall_score, f1_score, roc_auc_score, classification_report,balanced_accuracy_score, precision_recall_curve, plot_precision_recall_curve\n",
    "from utils import *\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing import sequence\n",
    "import torch\n",
    "from torch import optim\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ebdd26",
   "metadata": {},
   "source": [
    "# Read the Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca5e0f",
   "metadata": {},
   "source": [
    "### HASOC Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24d7529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label;clean_tweet;Hash Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0;murder let u bombard;#murderer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0;funni attack doctor happen nonbjp state medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0;think focu upheld spo man sprit rather glove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0;arrog refus turn c4debat allerg debat hust b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0;minut left almond oneplus7pro avail sbi cash...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        label;clean_tweet;Hash Words\n",
       "0                   0;murder let u bombard;#murderer\n",
       "1  0;funni attack doctor happen nonbjp state medi...\n",
       "2  0;think focu upheld spo man sprit rather glove...\n",
       "3  0;arrog refus turn c4debat allerg debat hust b...\n",
       "4  0;minut left almond oneplus7pro avail sbi cash..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasoc = pd.read_csv('data/Cleaning/HASOC_Dataset.csv',on_bad_lines='skip')\n",
    "hasoc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a726a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasoc= hasoc.rename(columns={'label;clean_tweet;Hash Words': 'temp'})\n",
    "hasoc= hasoc.temp.str.split(\";\",expand=True)\n",
    "hasoc.columns = ['label', 'text', 'hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61894ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>murder let u bombard</td>\n",
       "      <td>#murderer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>funni attack doctor happen nonbjp state medium...</td>\n",
       "      <td>#doctorsfightback #bengalviolence #kerala #doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>think focu upheld spo man sprit rather glove s...</td>\n",
       "      <td>#suppodhoni #dhonikeepstheglove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>arrog refus turn c4debat allerg debat hust bor...</td>\n",
       "      <td>#c4debate. #borisjohnsonshouldnotbepm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>minut left almond oneplus7pro avail sbi cash b...</td>\n",
       "      <td>#oneplus7pro #sbi #oneplus7 #oneplus7ishere #o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>0</td>\n",
       "      <td>lost polit good momotah hatao doctorsfightback</td>\n",
       "      <td>#doctorsfightback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>0</td>\n",
       "      <td>world cup go icc shameonicc</td>\n",
       "      <td>#shameonicc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>0</td>\n",
       "      <td>whitehous visit year wethenoh fucktrump</td>\n",
       "      <td>#wethenoh #fucktrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>0</td>\n",
       "      <td>made ok nazi fucktrump hope spend next bihday ...</td>\n",
       "      <td>#fucktrump.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4641</th>\n",
       "      <td>1</td>\n",
       "      <td>nonbailableoffence12yrsjail noth le doctorsfig...</td>\n",
       "      <td>#nonbailable_offence_12yrsjail #doctorsfightba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4642 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "0        0                               murder let u bombard   \n",
       "1        0  funni attack doctor happen nonbjp state medium...   \n",
       "2        0  think focu upheld spo man sprit rather glove s...   \n",
       "3        0  arrog refus turn c4debat allerg debat hust bor...   \n",
       "4        0  minut left almond oneplus7pro avail sbi cash b...   \n",
       "...    ...                                                ...   \n",
       "4637     0     lost polit good momotah hatao doctorsfightback   \n",
       "4638     0                        world cup go icc shameonicc   \n",
       "4639     0            whitehous visit year wethenoh fucktrump   \n",
       "4640     0  made ok nazi fucktrump hope spend next bihday ...   \n",
       "4641     1  nonbailableoffence12yrsjail noth le doctorsfig...   \n",
       "\n",
       "                                               hashtags  \n",
       "0                                             #murderer  \n",
       "1     #doctorsfightback #bengalviolence #kerala #doc...  \n",
       "2                       #suppodhoni #dhonikeepstheglove  \n",
       "3                 #c4debate. #borisjohnsonshouldnotbepm  \n",
       "4     #oneplus7pro #sbi #oneplus7 #oneplus7ishere #o...  \n",
       "...                                                 ...  \n",
       "4637                                  #doctorsfightback  \n",
       "4638                                        #shameonicc  \n",
       "4639                               #wethenoh #fucktrump  \n",
       "4640                                        #fucktrump.  \n",
       "4641  #nonbailable_offence_12yrsjail #doctorsfightba...  \n",
       "\n",
       "[4642 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7ae41fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3523\n",
       "1    1119\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasoc.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3596898",
   "metadata": {},
   "source": [
    "### Aristotle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd69393c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label;clean_tweet;Hash Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1;found transpond snail exclus shot skypiea ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0;logic treasuri sign deal even exist provid g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0;result risen isil dateoveral end sta chang b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0;nowplay onair 90 actuel sur live run water s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1;democrat never thisthey wrote law could read...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        label;clean_tweet;Hash Words\n",
       "0  1;found transpond snail exclus shot skypiea ka...\n",
       "1  0;logic treasuri sign deal even exist provid g...\n",
       "2  0;result risen isil dateoveral end sta chang b...\n",
       "3  0;nowplay onair 90 actuel sur live run water s...\n",
       "4  1;democrat never thisthey wrote law could read..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aris = pd.read_csv('data/Cleaning/Aristotle_Dataset.csv',on_bad_lines='skip')\n",
    "aris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33980f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>found transpond snail exclus shot skypiea kami...</td>\n",
       "      <td>#trecru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>logic treasuri sign deal even exist provid gua...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>result risen isil dateoveral end sta chang big</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>nowplay onair 90 actuel sur live run water sme...</td>\n",
       "      <td>#nowplaying #onair #90s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>democrat never thisthey wrote law could read t...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>0</td>\n",
       "      <td>omg see bigol gt star 4 n share</td>\n",
       "      <td>#bigolive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7076</th>\n",
       "      <td>1</td>\n",
       "      <td>take pleasur insult hindu sad exist one conve ...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>0</td>\n",
       "      <td>made remind 45 well promisebreak</td>\n",
       "      <td>#promisebreaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7078</th>\n",
       "      <td>1</td>\n",
       "      <td>everyth lie one degre anoth real truth even ey...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>0</td>\n",
       "      <td>preacger curl one best way develop bicep th el...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7080 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "0        1  found transpond snail exclus shot skypiea kami...   \n",
       "1        0  logic treasuri sign deal even exist provid gua...   \n",
       "2        0     result risen isil dateoveral end sta chang big   \n",
       "3        0  nowplay onair 90 actuel sur live run water sme...   \n",
       "4        1  democrat never thisthey wrote law could read t...   \n",
       "...    ...                                                ...   \n",
       "7075     0                    omg see bigol gt star 4 n share   \n",
       "7076     1  take pleasur insult hindu sad exist one conve ...   \n",
       "7077     0                   made remind 45 well promisebreak   \n",
       "7078     1  everyth lie one degre anoth real truth even ey...   \n",
       "7079     0  preacger curl one best way develop bicep th el...   \n",
       "\n",
       "                     hashtags  \n",
       "0                     #trecru  \n",
       "1                 No hashtags  \n",
       "2                 No hashtags  \n",
       "3     #nowplaying #onair #90s  \n",
       "4                 No hashtags  \n",
       "...                       ...  \n",
       "7075                #bigolive  \n",
       "7076              No hashtags  \n",
       "7077          #promisebreaker  \n",
       "7078              No hashtags  \n",
       "7079              No hashtags  \n",
       "\n",
       "[7080 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aris= aris.rename(columns={'label;clean_tweet;Hash Words': 'temp'})\n",
    "aris= aris.temp.str.split(\";\",expand=True)\n",
    "aris.columns = ['label', 'text', 'hashtags']\n",
    "aris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d80c0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5542\n",
       "1    1538\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aris.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29ff9f",
   "metadata": {},
   "source": [
    "### Hugging Face Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32f0790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label;clean_tweet;Hash Words;;'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf = pd.read_csv('data/Cleaning/HuggingFace_Dataset.csv',on_bad_lines='skip')\n",
    "hf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc311966",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf= hf.rename(columns={'label;clean_tweet;Hash Words;;': 'temp'})\n",
    "hf= hf.temp.str.split(\";\",expand=True)\n",
    "hf.columns = ['label', 'text', 'hashtags','temp1','temp2']\n",
    "hf.drop(columns=['temp1','temp2'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d50c12f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28859\n",
       "1     2087\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e75e0",
   "metadata": {},
   "source": [
    "### Copenhagen Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d628a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label;clean_tweet;Hash Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0;new mascot;No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0;cook public safe option good option want peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0;one said threat seriou howev differ isi game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0;disneyland realli;No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1;vagina tri funni;No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        label;clean_tweet;Hash Words\n",
       "0                           0;new mascot;No hashtags\n",
       "1  0;cook public safe option good option want peo...\n",
       "2  0;one said threat seriou howev differ isi game...\n",
       "3                    0;disneyland realli;No hashtags\n",
       "4                     1;vagina tri funni;No hashtags"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copen = pd.read_csv('data/Cleaning/Copenhagen_Dataset.csv',on_bad_lines='skip')\n",
    "copen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c441dc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>new mascot</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cook public safe option good option want peopl...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>one said threat seriou howev differ isi gamerg</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>disneyland realli</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>vagina tri funni</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>0</td>\n",
       "      <td>go npo never get rich p goal make enough live ...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>0</td>\n",
       "      <td>yeah men never talk shit know noth like bih co...</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>0</td>\n",
       "      <td>someon realli want keep</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>1</td>\n",
       "      <td>yup</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>0</td>\n",
       "      <td>congrat find bug sure gamerg tote go care</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9876 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text     hashtags\n",
       "0        0                                         new mascot  No hashtags\n",
       "1        0  cook public safe option good option want peopl...  No hashtags\n",
       "2        0     one said threat seriou howev differ isi gamerg  No hashtags\n",
       "3        0                                  disneyland realli  No hashtags\n",
       "4        1                                   vagina tri funni  No hashtags\n",
       "...    ...                                                ...          ...\n",
       "9871     0  go npo never get rich p goal make enough live ...  No hashtags\n",
       "9872     0  yeah men never talk shit know noth like bih co...  No hashtags\n",
       "9873     0                            someon realli want keep  No hashtags\n",
       "9874     1                                                yup  No hashtags\n",
       "9875     0          congrat find bug sure gamerg tote go care  No hashtags\n",
       "\n",
       "[9876 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copen= copen.rename(columns={'label;clean_tweet;Hash Words': 'temp'})\n",
    "copen= copen.temp.str.split(\";\",expand=True)\n",
    "copen.columns = ['label', 'text', 'hashtags']\n",
    "copen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74b90a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7210\n",
       "1    2666\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copen.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10007b6a",
   "metadata": {},
   "source": [
    "# Train and Test Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d358eb9",
   "metadata": {},
   "source": [
    "### Hugging Face Dataset to Train and Others to Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da3fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_x_train = hf.text\n",
    "hasoc_x_test = hasoc.text\n",
    "aris_x_test = aris.text\n",
    "copen_x_test = copen.text\n",
    "\n",
    "hf_y_train = hf.label\n",
    "hasoc_y_test = hasoc.label\n",
    "aris_y_test = aris.label\n",
    "copen_y_test = copen.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e289a3",
   "metadata": {},
   "source": [
    "### Implement TFIDF for Unshuffled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf4316e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "tfidf_tr = vec.fit_transform(hf_x_train)\n",
    "tfidf_hasoc_test = vec.transform(hasoc_x_test)\n",
    "tfidf_aris_test = vec.transform(aris_x_test)\n",
    "tfidf_copen_test = vec.transform(copen_x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b30dbc",
   "metadata": {},
   "source": [
    "### Shuffle the Data for Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d03e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_shuffle = hf.sample(frac=1)\n",
    "hasoc_shuffle = hasoc.sample(frac=1)\n",
    "aris_shuffle = aris.sample(frac=1)\n",
    "copen_shuffle = copen.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6979fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_x_train_shuffle = hf_shuffle.text\n",
    "hasoc_x_test_shuffle = hasoc_shuffle.text\n",
    "aris_x_test_shuffle = aris_shuffle.text\n",
    "copen_x_test_shuffle = copen_shuffle.text\n",
    "\n",
    "hf_y_train_shuffle = hf_shuffle.label\n",
    "hasoc_y_test_shuffle = hasoc_shuffle.label\n",
    "aris_y_test_shuffle = aris_shuffle.label\n",
    "copen_y_test_shuffle = copen_shuffle.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff306674",
   "metadata": {},
   "source": [
    "### Implement TFIDF for Shuffled Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e35eacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer()\n",
    "tfidf_tr_shuffle = vec.fit_transform(hf_x_train_shuffle)\n",
    "tfidf_hasoc_test_shuffle = vec.transform(hasoc_x_test_shuffle)\n",
    "tfidf_aris_test_shuffle = vec.transform(aris_x_test_shuffle)\n",
    "tfidf_copen_test_shuffle = vec.transform(copen_x_test_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5d90c",
   "metadata": {},
   "source": [
    "# Artifical Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bc8487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_y_train_encode = preprocessing.LabelEncoder().fit_transform(hf_y_train_shuffle)\n",
    "hasoc_y_test_encode = preprocessing. LabelEncoder().fit_transform(hasoc_y_test_shuffle)\n",
    "aris_y_test_encode = preprocessing. LabelEncoder().fit_transform(aris_y_test_shuffle)\n",
    "copen_y_test_encode = preprocessing. LabelEncoder().fit_transform(copen_y_test_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b575c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_x_train = scipy.sparse.csr_matrix.todense(tfidf_tr_shuffle)\n",
    "hasoc_x_test = scipy.sparse.csr_matrix.todense(tfidf_hasoc_test_shuffle)\n",
    "aris_x_test = scipy.sparse.csr_matrix.todense(tfidf_aris_test_shuffle)\n",
    "copen_x_test = scipy.sparse.csr_matrix.todense(tfidf_copen_test_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ffe4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit the model\n",
    "def get_model(trainX,trainy):\n",
    " # define model\n",
    "    model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(128, activation='relu', input_shape=(trainX.shape[1],)),\n",
    "                            tf.keras.layers.Dropout(0.2),\n",
    "                            tf.keras.layers.Dense(32, activation='relu'),\n",
    "                            tf.keras.layers.Dropout(0.2),\n",
    "                            tf.keras.layers.Dense(128, activation='softmax')])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(trainX, trainy, epochs=10, verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bacc9b",
   "metadata": {},
   "source": [
    "### Use HASOC to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03b1b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:44:23.503102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "968/968 - 7s - loss: 0.4044 - accuracy: 0.9423 - 7s/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "968/968 - 7s - loss: 0.0700 - accuracy: 0.9767 - 7s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "968/968 - 7s - loss: 0.0324 - accuracy: 0.9891 - 7s/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "968/968 - 7s - loss: 0.0158 - accuracy: 0.9949 - 7s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "968/968 - 7s - loss: 0.0086 - accuracy: 0.9974 - 7s/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "968/968 - 7s - loss: 0.0055 - accuracy: 0.9985 - 7s/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "968/968 - 7s - loss: 0.0032 - accuracy: 0.9990 - 7s/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "968/968 - 7s - loss: 0.0018 - accuracy: 0.9994 - 7s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "968/968 - 7s - loss: 0.0019 - accuracy: 0.9995 - 7s/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "968/968 - 7s - loss: 0.0011 - accuracy: 0.9996 - 7s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "ann_model = get_model(hf_x_train,hf_y_train_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "030ff176",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hasoc_predict = ann_model.predict(hasoc_x_test,verbose=0)\n",
    "y_predict_hasoc_classes=np.argmax(y_hasoc_predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f7f1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6809564842740198\n",
      "F1:  0.1512893982808023\n",
      "Recall:  0.11796246648793565\n",
      "Precision:  0.2108626198083067\n",
      "ROC-AUC:  0.48887053213695675\n",
      "PR-AUC:  0.237497743744669\n"
     ]
    }
   ],
   "source": [
    "ann_Evaluation(hasoc_y_test_encode, y_predict_hasoc_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b72bd",
   "metadata": {},
   "source": [
    "### Use Aristotle Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63136657",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aris_predict = ann_model.predict(aris_x_test,verbose=0)\n",
    "y_predict_aris_classes=np.argmax(y_aris_predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "386d3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7816384180790961\n",
      "F1:  0.2262262262262262\n",
      "Recall:  0.1469440832249675\n",
      "Precision:  0.49130434782608695\n",
      "ROC-AUC:  0.5523605295229854\n",
      "PR-AUC:  0.2575050014390217\n"
     ]
    }
   ],
   "source": [
    "ann_Evaluation(aris_y_test_encode, y_predict_aris_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c7e954",
   "metadata": {},
   "source": [
    "### Use Copenhagen Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bed0b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_copen_predict = ann_model.predict(copen_x_test,verbose=0)\n",
    "y_predict_copen_classes=np.argmax(y_copen_predict,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a618f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7562778452814904\n",
      "F1:  0.3876876112948359\n",
      "Recall:  0.28582145536384096\n",
      "Precision:  0.6023715415019762\n",
      "ROC-AUC:  0.6080286194988415\n",
      "PR-AUC:  0.36496131414504673\n"
     ]
    }
   ],
   "source": [
    "ann_Evaluation(copen_y_test_encode, y_predict_copen_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4d0d1",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f2d8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100).fit(tfidf_tr, hf_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ca6b7",
   "metadata": {},
   "source": [
    "### Use HASOC to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d39887b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7397673416630762\n",
      "F1 Score:  0.0944527736131934\n",
      "ROC-AUC:  0.5124972192184285\n",
      "Recall:  0.05630026809651475\n",
      "Precision:  0.2930232558139535\n",
      "PR-AUC:  0.2496060623866653\n"
     ]
    }
   ],
   "source": [
    "hasoc_rf_test = rf.predict(tfidf_hasoc_test)\n",
    "get_metrics_confusion(tfidf_hasoc_test, hasoc_y_test, hasoc_rf_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49c4fa",
   "metadata": {},
   "source": [
    "### Use Aristotle Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b56ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7879943502824859\n",
      "F1 Score:  0.11861421021726362\n",
      "ROC-AUC:  0.7088533994337601\n",
      "Recall:  0.06566970091027308\n",
      "Precision:  0.6121212121212121\n",
      "PR-AUC:  0.39234347640983047\n"
     ]
    }
   ],
   "source": [
    "aris_rf_test = rf.predict(tfidf_aris_test)\n",
    "get_metrics_confusion(tfidf_aris_test, aris_y_test, aris_rf_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cea9a7",
   "metadata": {},
   "source": [
    "### Use Copenhagen Dataset to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f41b73d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7996152288375861\n",
      "F1 Score:  0.47296937416777624\n",
      "ROC-AUC:  0.7245990242359481\n",
      "Recall:  0.33308327081770445\n",
      "Precision:  0.8154269972451791\n",
      "PR-AUC:  0.5713141207204333\n"
     ]
    }
   ],
   "source": [
    "copen_rf_test = rf.predict(tfidf_copen_test)\n",
    "get_metrics_confusion(tfidf_copen_test, copen_y_test, copen_rf_test, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e2aa1",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcd2bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.LinearSVC(random_state=42).fit(tfidf_tr, hf_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc94cc5f",
   "metadata": {},
   "source": [
    "### Use HASOC to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccfc75a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7156398104265402\n",
      "F1:  0.12928759894459105\n",
      "Recall:  0.08757819481680071\n",
      "Precision:  0.24685138539042822\n",
      "ROC-AUC:  0.5037936582706722\n",
      "PR-AUC:  0.2506970111854758\n"
     ]
    }
   ],
   "source": [
    "hasoc_svc_test = svc.predict(tfidf_hasoc_test)\n",
    "get_metrics_2(tfidf_hasoc_test, hasoc_y_test, hasoc_svc_test, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f16b2e",
   "metadata": {},
   "source": [
    "### Use Aristotle Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a971d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7889830508474577\n",
      "F1:  0.1827133479212254\n",
      "Recall:  0.10858257477243173\n",
      "Precision:  0.5758620689655173\n",
      "ROC-AUC:  0.6810545103263927\n",
      "PR-AUC:  0.38254934906360244\n"
     ]
    }
   ],
   "source": [
    "aris_svc_test = svc.predict(tfidf_aris_test)\n",
    "get_metrics_2(tfidf_aris_test, aris_y_test, aris_svc_test, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d3fecd",
   "metadata": {},
   "source": [
    "### Use Copenhagen Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bea9dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7775415147833131\n",
      "F1:  0.405090712158137\n",
      "Recall:  0.2805701425356339\n",
      "Precision:  0.7283349561830574\n",
      "ROC-AUC:  0.7178558942787016\n",
      "PR-AUC:  0.5427381183279067\n"
     ]
    }
   ],
   "source": [
    "copen_svc_test = svc.predict(tfidf_copen_test)\n",
    "get_metrics_2(tfidf_copen_test, copen_y_test, copen_svc_test, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f36bc2",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0612e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(tfidf_tr, hf_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13da72b",
   "metadata": {},
   "source": [
    "### Use HASOC to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e0e8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasoc_nb_test = nb.predict(tfidf_hasoc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2809f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7585092632485998\n",
      "F1 Score:  0.0070859167404783\n",
      "ROC-AUC:  0.47425941159803436\n",
      "Recall:  0.0035746201966041107\n",
      "Precision:  0.4\n",
      "PR-AUC:  0.2274568832318805\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_hasoc_test, hasoc_y_test, hasoc_nb_test, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee8d71",
   "metadata": {},
   "source": [
    "###  Use Aristotle Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "131cace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aris_nb_test = nb.predict(tfidf_aris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95e0f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782909604519774\n",
      "F1 Score:  0.001299545159194282\n",
      "ROC-AUC:  0.6346916841201765\n",
      "Recall:  0.0006501950585175553\n",
      "Precision:  1.0\n",
      "PR-AUC:  0.31763151362702025\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_aris_test, aris_y_test, aris_nb_test, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c2fe9",
   "metadata": {},
   "source": [
    "### Use Copenhagen Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d03dea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "copen_nb_test = nb.predict(tfidf_copen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a5225fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7300526528959093\n",
      "F1 Score:  0.0007496251874062968\n",
      "ROC-AUC:  0.6282697408055203\n",
      "Recall:  0.00037509377344336085\n",
      "Precision:  0.5\n",
      "PR-AUC:  0.3903570018342335\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_copen_test, copen_y_test, copen_nb_test, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e39d92",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7f67d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression().fit(tfidf_tr, hf_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623dd962",
   "metadata": {},
   "source": [
    "### Use HASOC to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2723f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasoc_log_test = log.predict(tfidf_hasoc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41c7d89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7462300732442912\n",
      "F1 Score:  0.05152979066022545\n",
      "ROC-AUC:  0.5182732544999197\n",
      "Recall:  0.028596961572832886\n",
      "Precision:  0.2601626016260163\n",
      "PR-AUC:  0.25332573986045753\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_hasoc_test, hasoc_y_test, hasoc_log_test, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e7b617",
   "metadata": {},
   "source": [
    "### Use Aristotle Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53014a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "aris_log_test = log.predict(tfidf_aris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74637ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7877118644067796\n",
      "F1 Score:  0.08409506398537478\n",
      "ROC-AUC:  0.7233732687471345\n",
      "Recall:  0.044863459037711315\n",
      "Precision:  0.6699029126213593\n",
      "PR-AUC:  0.434280330515161\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_aris_test, aris_y_test, aris_log_test, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2978d07",
   "metadata": {},
   "source": [
    "### Use Copenhagen Dataset to Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed9a7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "copen_log_test = log.predict(tfidf_copen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b40403fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.743215876873228\n",
      "F1 Score:  0.1484217595701813\n",
      "ROC-AUC:  0.714625639766391\n",
      "Recall:  0.08289572393098274\n",
      "Precision:  0.7083333333333334\n",
      "PR-AUC:  0.5018639536322111\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_copen_test, copen_y_test, copen_log_test, log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dec59f",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a83ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier().fit(tfidf_tr, hf_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e7a60",
   "metadata": {},
   "source": [
    "### Use HASOC to Test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80508878",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasoc_gbc_test = gbc.predict(tfidf_hasoc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0599fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7539853511417492\n",
      "F1 Score:  0.035472972972972965\n",
      "ROC-AUC:  0.5055505287987505\n",
      "Recall:  0.01876675603217158\n",
      "Precision:  0.3230769230769231\n",
      "PR-AUC:  0.24900747237360282\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_hasoc_test, hasoc_y_test, hasoc_gbc_test,gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58252753",
   "metadata": {},
   "source": [
    "### Use Aristotle Dataset to Test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fde8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "aris_gbc_test = gbc.predict(tfidf_aris_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "197e571e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7854519774011299\n",
      "F1 Score:  0.06523076923076923\n",
      "ROC-AUC:  0.6477778862348708\n",
      "Recall:  0.03446033810143043\n",
      "Precision:  0.6091954022988506\n",
      "PR-AUC:  0.33989571603967006\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_aris_test, aris_y_test, aris_gbc_test,gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50ee6d",
   "metadata": {},
   "source": [
    "### Use Copenhagen Dataset to Test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "513c9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "copen_gbc_test = gbc.predict(tfidf_copen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0404dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7382543539894694\n",
      "F1 Score:  0.09710094306671324\n",
      "ROC-AUC:  0.6933008304087117\n",
      "Recall:  0.052138034508627154\n",
      "Precision:  0.7055837563451777\n",
      "PR-AUC:  0.4763762784731524\n"
     ]
    }
   ],
   "source": [
    "get_metrics_confusion(tfidf_copen_test, copen_y_test, copen_gbc_test,gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8213c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
